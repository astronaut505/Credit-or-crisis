{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Me\\AppData\\Local\\Temp\\ipykernel_14752\\2582827541.py:7: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = pd.read_csv('data/train.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SSN</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <th>...</th>\n",
       "      <th>Credit_Mix</th>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <th>Credit_History_Age</th>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <th>Credit_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x1602</td>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>January</td>\n",
       "      <td>Aaron Maashoh</td>\n",
       "      <td>23</td>\n",
       "      <td>821-00-0265</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>_</td>\n",
       "      <td>809.98</td>\n",
       "      <td>26.822620</td>\n",
       "      <td>22 Years and 1 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>80.41529543900253</td>\n",
       "      <td>High_spent_Small_value_payments</td>\n",
       "      <td>312.49408867943663</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x1603</td>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>February</td>\n",
       "      <td>Aaron Maashoh</td>\n",
       "      <td>23</td>\n",
       "      <td>821-00-0265</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.944960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>118.28022162236736</td>\n",
       "      <td>Low_spent_Large_value_payments</td>\n",
       "      <td>284.62916249607184</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1604</td>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>March</td>\n",
       "      <td>Aaron Maashoh</td>\n",
       "      <td>-500</td>\n",
       "      <td>821-00-0265</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>28.609352</td>\n",
       "      <td>22 Years and 3 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>81.699521264648</td>\n",
       "      <td>Low_spent_Medium_value_payments</td>\n",
       "      <td>331.2098628537912</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1605</td>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>April</td>\n",
       "      <td>Aaron Maashoh</td>\n",
       "      <td>23</td>\n",
       "      <td>821-00-0265</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.377862</td>\n",
       "      <td>22 Years and 4 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>199.4580743910713</td>\n",
       "      <td>Low_spent_Small_value_payments</td>\n",
       "      <td>223.45130972736786</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x1606</td>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>May</td>\n",
       "      <td>Aaron Maashoh</td>\n",
       "      <td>23</td>\n",
       "      <td>821-00-0265</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>24.797347</td>\n",
       "      <td>22 Years and 5 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>41.420153086217326</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>341.48923103222177</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x1607</td>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>June</td>\n",
       "      <td>Aaron Maashoh</td>\n",
       "      <td>23</td>\n",
       "      <td>821-00-0265</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>27.262259</td>\n",
       "      <td>22 Years and 6 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>62.430172331195294</td>\n",
       "      <td>!@9#%8</td>\n",
       "      <td>340.4792117872438</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0x1608</td>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>July</td>\n",
       "      <td>Aaron Maashoh</td>\n",
       "      <td>23</td>\n",
       "      <td>821-00-0265</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>22.537593</td>\n",
       "      <td>22 Years and 7 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>178.3440674122349</td>\n",
       "      <td>Low_spent_Small_value_payments</td>\n",
       "      <td>244.5653167062043</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0x1609</td>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>August</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>#F%$D@*&amp;8</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>23.933795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>24.785216509052056</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>358.12416760938714</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0x160e</td>\n",
       "      <td>CUS_0x21b1</td>\n",
       "      <td>January</td>\n",
       "      <td>Rick Rothackerj</td>\n",
       "      <td>28_</td>\n",
       "      <td>004-07-5839</td>\n",
       "      <td>_______</td>\n",
       "      <td>34847.84</td>\n",
       "      <td>3037.986667</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>605.03</td>\n",
       "      <td>24.464031</td>\n",
       "      <td>26 Years and 7 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>18.816215</td>\n",
       "      <td>104.291825168246</td>\n",
       "      <td>Low_spent_Small_value_payments</td>\n",
       "      <td>470.69062692529184</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0x160f</td>\n",
       "      <td>CUS_0x21b1</td>\n",
       "      <td>February</td>\n",
       "      <td>Rick Rothackerj</td>\n",
       "      <td>28</td>\n",
       "      <td>004-07-5839</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>34847.84</td>\n",
       "      <td>3037.986667</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>605.03</td>\n",
       "      <td>38.550848</td>\n",
       "      <td>26 Years and 8 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>18.816215</td>\n",
       "      <td>40.39123782853101</td>\n",
       "      <td>High_spent_Large_value_payments</td>\n",
       "      <td>484.5912142650067</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0x1610</td>\n",
       "      <td>CUS_0x21b1</td>\n",
       "      <td>March</td>\n",
       "      <td>Rick Rothackerj</td>\n",
       "      <td>28</td>\n",
       "      <td>004-07-5839</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>34847.84_</td>\n",
       "      <td>3037.986667</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>_</td>\n",
       "      <td>605.03</td>\n",
       "      <td>33.224951</td>\n",
       "      <td>26 Years and 9 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>18.816215</td>\n",
       "      <td>58.51597569589465</td>\n",
       "      <td>High_spent_Large_value_payments</td>\n",
       "      <td>466.46647639764313</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0x1611</td>\n",
       "      <td>CUS_0x21b1</td>\n",
       "      <td>April</td>\n",
       "      <td>Rick Rothackerj</td>\n",
       "      <td>28</td>\n",
       "      <td>004-07-5839</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>34847.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>605.03</td>\n",
       "      <td>39.182656</td>\n",
       "      <td>26 Years and 10 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>18.816215</td>\n",
       "      <td>99.30622796053305</td>\n",
       "      <td>Low_spent_Medium_value_payments</td>\n",
       "      <td>465.6762241330048</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0x1612</td>\n",
       "      <td>CUS_0x21b1</td>\n",
       "      <td>May</td>\n",
       "      <td>Rick Rothackerj</td>\n",
       "      <td>28</td>\n",
       "      <td>004-07-5839</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>34847.84</td>\n",
       "      <td>3037.986667</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>605.03</td>\n",
       "      <td>34.977895</td>\n",
       "      <td>26 Years and 11 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>18.816215</td>\n",
       "      <td>130.11542024292334</td>\n",
       "      <td>Low_spent_Small_value_payments</td>\n",
       "      <td>444.8670318506144</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0x1613</td>\n",
       "      <td>CUS_0x21b1</td>\n",
       "      <td>June</td>\n",
       "      <td>Rick Rothackerj</td>\n",
       "      <td>28</td>\n",
       "      <td>004-07-5839</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>34847.84</td>\n",
       "      <td>3037.986667</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>605.03</td>\n",
       "      <td>33.381010</td>\n",
       "      <td>27 Years and 0 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>18.816215</td>\n",
       "      <td>43.477190144355745</td>\n",
       "      <td>High_spent_Large_value_payments</td>\n",
       "      <td>481.505261949182</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0x1614</td>\n",
       "      <td>CUS_0x21b1</td>\n",
       "      <td>July</td>\n",
       "      <td>Rick Rothackerj</td>\n",
       "      <td>28</td>\n",
       "      <td>004-07-5839</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>34847.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>605.03</td>\n",
       "      <td>31.131702</td>\n",
       "      <td>27 Years and 1 Months</td>\n",
       "      <td>NM</td>\n",
       "      <td>18.816215</td>\n",
       "      <td>70.10177420755677</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>464.8806778859809</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0x1615</td>\n",
       "      <td>CUS_0x21b1</td>\n",
       "      <td>August</td>\n",
       "      <td>Rick Rothackerj</td>\n",
       "      <td>28</td>\n",
       "      <td>004-07-5839</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>34847.84</td>\n",
       "      <td>3037.986667</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>605.03</td>\n",
       "      <td>32.933856</td>\n",
       "      <td>27 Years and 2 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>18.816215</td>\n",
       "      <td>218.90434353388733</td>\n",
       "      <td>Low_spent_Small_value_payments</td>\n",
       "      <td>356.07810855965045</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0x161a</td>\n",
       "      <td>CUS_0x2dbc</td>\n",
       "      <td>January</td>\n",
       "      <td>Langep</td>\n",
       "      <td>34</td>\n",
       "      <td>486-85-3974</td>\n",
       "      <td>_______</td>\n",
       "      <td>143162.64</td>\n",
       "      <td>12187.220000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>1303.01</td>\n",
       "      <td>28.616735</td>\n",
       "      <td>17 Years and 9 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>246.992319</td>\n",
       "      <td>168.413702679309</td>\n",
       "      <td>!@9#%8</td>\n",
       "      <td>1043.3159778669492</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0x161b</td>\n",
       "      <td>CUS_0x2dbc</td>\n",
       "      <td>February</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>486-85-3974</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>143162.64</td>\n",
       "      <td>12187.220000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>1303.01</td>\n",
       "      <td>41.702573</td>\n",
       "      <td>17 Years and 10 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>246.992319</td>\n",
       "      <td>232.86038375993544</td>\n",
       "      <td>High_spent_Small_value_payments</td>\n",
       "      <td>998.8692967863226</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0x161c</td>\n",
       "      <td>CUS_0x2dbc</td>\n",
       "      <td>March</td>\n",
       "      <td>Langep</td>\n",
       "      <td>34</td>\n",
       "      <td>486-85-3974</td>\n",
       "      <td>_______</td>\n",
       "      <td>143162.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>1303.01</td>\n",
       "      <td>26.519815</td>\n",
       "      <td>17 Years and 11 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>246.992319</td>\n",
       "      <td>__10000__</td>\n",
       "      <td>High_spent_Small_value_payments</td>\n",
       "      <td>715.741367403555</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0x161d</td>\n",
       "      <td>CUS_0x2dbc</td>\n",
       "      <td>April</td>\n",
       "      <td>Langep</td>\n",
       "      <td>34</td>\n",
       "      <td>486-85-3974</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>143162.64</td>\n",
       "      <td>12187.220000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>_</td>\n",
       "      <td>1303.01</td>\n",
       "      <td>39.501648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>246.992319</td>\n",
       "      <td>825.2162699393922</td>\n",
       "      <td>Low_spent_Medium_value_payments</td>\n",
       "      <td>426.5134106068658</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0x161e</td>\n",
       "      <td>CUS_0x2dbc</td>\n",
       "      <td>May</td>\n",
       "      <td>Langep</td>\n",
       "      <td>34</td>\n",
       "      <td>486-85-3974</td>\n",
       "      <td>_______</td>\n",
       "      <td>143162.64</td>\n",
       "      <td>12187.220000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>1303.01</td>\n",
       "      <td>31.376150</td>\n",
       "      <td>18 Years and 1 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>246.992319</td>\n",
       "      <td>430.9475278803298</td>\n",
       "      <td>Low_spent_Large_value_payments</td>\n",
       "      <td>810.7821526659284</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0x161f</td>\n",
       "      <td>CUS_0x2dbc</td>\n",
       "      <td>June</td>\n",
       "      <td>Langep</td>\n",
       "      <td>34</td>\n",
       "      <td>486-85-3974</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>143162.64</td>\n",
       "      <td>12187.220000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>1303.01</td>\n",
       "      <td>39.783993</td>\n",
       "      <td>18 Years and 2 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>246.992319</td>\n",
       "      <td>257.80809942568976</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>963.9215811205684</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0x1620</td>\n",
       "      <td>CUS_0x2dbc</td>\n",
       "      <td>July</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>486-85-3974</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>143162.64</td>\n",
       "      <td>12187.220000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>1303.01</td>\n",
       "      <td>38.068624</td>\n",
       "      <td>18 Years and 3 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>246.992319</td>\n",
       "      <td>263.17416316163934</td>\n",
       "      <td>High_spent_Small_value_payments</td>\n",
       "      <td>968.5555173846187</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0x1621</td>\n",
       "      <td>CUS_0x2dbc</td>\n",
       "      <td>August</td>\n",
       "      <td>Langep</td>\n",
       "      <td>34</td>\n",
       "      <td>486-85-3974</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>143162.64</td>\n",
       "      <td>12187.220000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>1303.01</td>\n",
       "      <td>38.374753</td>\n",
       "      <td>18 Years and 4 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>246.992319</td>\n",
       "      <td>__10000__</td>\n",
       "      <td>High_spent_Small_value_payments</td>\n",
       "      <td>895.494583180492</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0x1626</td>\n",
       "      <td>CUS_0xb891</td>\n",
       "      <td>January</td>\n",
       "      <td>Jasond</td>\n",
       "      <td>54</td>\n",
       "      <td>072-31-6145</td>\n",
       "      <td>Entrepreneur</td>\n",
       "      <td>30689.89</td>\n",
       "      <td>2612.490833</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>632.46</td>\n",
       "      <td>26.544229</td>\n",
       "      <td>17 Years and 3 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>16.415452</td>\n",
       "      <td>81.22885871073616</td>\n",
       "      <td>Low_spent_Large_value_payments</td>\n",
       "      <td>433.6047729627723</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID Customer_ID     Month             Name   Age          SSN  \\\n",
       "0   0x1602   CUS_0xd40   January    Aaron Maashoh    23  821-00-0265   \n",
       "1   0x1603   CUS_0xd40  February    Aaron Maashoh    23  821-00-0265   \n",
       "2   0x1604   CUS_0xd40     March    Aaron Maashoh  -500  821-00-0265   \n",
       "3   0x1605   CUS_0xd40     April    Aaron Maashoh    23  821-00-0265   \n",
       "4   0x1606   CUS_0xd40       May    Aaron Maashoh    23  821-00-0265   \n",
       "5   0x1607   CUS_0xd40      June    Aaron Maashoh    23  821-00-0265   \n",
       "6   0x1608   CUS_0xd40      July    Aaron Maashoh    23  821-00-0265   \n",
       "7   0x1609   CUS_0xd40    August              NaN    23    #F%$D@*&8   \n",
       "8   0x160e  CUS_0x21b1   January  Rick Rothackerj   28_  004-07-5839   \n",
       "9   0x160f  CUS_0x21b1  February  Rick Rothackerj    28  004-07-5839   \n",
       "10  0x1610  CUS_0x21b1     March  Rick Rothackerj    28  004-07-5839   \n",
       "11  0x1611  CUS_0x21b1     April  Rick Rothackerj    28  004-07-5839   \n",
       "12  0x1612  CUS_0x21b1       May  Rick Rothackerj    28  004-07-5839   \n",
       "13  0x1613  CUS_0x21b1      June  Rick Rothackerj    28  004-07-5839   \n",
       "14  0x1614  CUS_0x21b1      July  Rick Rothackerj    28  004-07-5839   \n",
       "15  0x1615  CUS_0x21b1    August  Rick Rothackerj    28  004-07-5839   \n",
       "16  0x161a  CUS_0x2dbc   January           Langep    34  486-85-3974   \n",
       "17  0x161b  CUS_0x2dbc  February              NaN    34  486-85-3974   \n",
       "18  0x161c  CUS_0x2dbc     March           Langep    34  486-85-3974   \n",
       "19  0x161d  CUS_0x2dbc     April           Langep    34  486-85-3974   \n",
       "20  0x161e  CUS_0x2dbc       May           Langep    34  486-85-3974   \n",
       "21  0x161f  CUS_0x2dbc      June           Langep    34  486-85-3974   \n",
       "22  0x1620  CUS_0x2dbc      July              NaN    34  486-85-3974   \n",
       "23  0x1621  CUS_0x2dbc    August           Langep    34  486-85-3974   \n",
       "24  0x1626  CUS_0xb891   January           Jasond    54  072-31-6145   \n",
       "\n",
       "      Occupation Annual_Income  Monthly_Inhand_Salary  Num_Bank_Accounts  ...  \\\n",
       "0      Scientist      19114.12            1824.843333                  3  ...   \n",
       "1      Scientist      19114.12                    NaN                  3  ...   \n",
       "2      Scientist      19114.12                    NaN                  3  ...   \n",
       "3      Scientist      19114.12                    NaN                  3  ...   \n",
       "4      Scientist      19114.12            1824.843333                  3  ...   \n",
       "5      Scientist      19114.12                    NaN                  3  ...   \n",
       "6      Scientist      19114.12            1824.843333                  3  ...   \n",
       "7      Scientist      19114.12            1824.843333                  3  ...   \n",
       "8        _______      34847.84            3037.986667                  2  ...   \n",
       "9        Teacher      34847.84            3037.986667                  2  ...   \n",
       "10       Teacher     34847.84_            3037.986667                  2  ...   \n",
       "11       Teacher      34847.84                    NaN                  2  ...   \n",
       "12       Teacher      34847.84            3037.986667                  2  ...   \n",
       "13       Teacher      34847.84            3037.986667                  2  ...   \n",
       "14       Teacher      34847.84                    NaN                  2  ...   \n",
       "15       Teacher      34847.84            3037.986667                  2  ...   \n",
       "16       _______     143162.64           12187.220000                  1  ...   \n",
       "17      Engineer     143162.64           12187.220000                  1  ...   \n",
       "18       _______     143162.64                    NaN                  1  ...   \n",
       "19      Engineer     143162.64           12187.220000                  1  ...   \n",
       "20       _______     143162.64           12187.220000                  1  ...   \n",
       "21      Engineer     143162.64           12187.220000                  1  ...   \n",
       "22      Engineer     143162.64           12187.220000                  1  ...   \n",
       "23      Engineer     143162.64           12187.220000                  1  ...   \n",
       "24  Entrepreneur      30689.89            2612.490833                  2  ...   \n",
       "\n",
       "    Credit_Mix  Outstanding_Debt Credit_Utilization_Ratio  \\\n",
       "0            _            809.98                26.822620   \n",
       "1         Good            809.98                31.944960   \n",
       "2         Good            809.98                28.609352   \n",
       "3         Good            809.98                31.377862   \n",
       "4         Good            809.98                24.797347   \n",
       "5         Good            809.98                27.262259   \n",
       "6         Good            809.98                22.537593   \n",
       "7         Good            809.98                23.933795   \n",
       "8         Good            605.03                24.464031   \n",
       "9         Good            605.03                38.550848   \n",
       "10           _            605.03                33.224951   \n",
       "11        Good            605.03                39.182656   \n",
       "12        Good            605.03                34.977895   \n",
       "13        Good            605.03                33.381010   \n",
       "14        Good            605.03                31.131702   \n",
       "15        Good            605.03                32.933856   \n",
       "16        Good           1303.01                28.616735   \n",
       "17        Good           1303.01                41.702573   \n",
       "18        Good           1303.01                26.519815   \n",
       "19           _           1303.01                39.501648   \n",
       "20        Good           1303.01                31.376150   \n",
       "21        Good           1303.01                39.783993   \n",
       "22        Good           1303.01                38.068624   \n",
       "23        Good           1303.01                38.374753   \n",
       "24        Good            632.46                26.544229   \n",
       "\n",
       "        Credit_History_Age  Payment_of_Min_Amount Total_EMI_per_month  \\\n",
       "0    22 Years and 1 Months                     No           49.574949   \n",
       "1                      NaN                     No           49.574949   \n",
       "2    22 Years and 3 Months                     No           49.574949   \n",
       "3    22 Years and 4 Months                     No           49.574949   \n",
       "4    22 Years and 5 Months                     No           49.574949   \n",
       "5    22 Years and 6 Months                     No           49.574949   \n",
       "6    22 Years and 7 Months                     No           49.574949   \n",
       "7                      NaN                     No           49.574949   \n",
       "8    26 Years and 7 Months                     No           18.816215   \n",
       "9    26 Years and 8 Months                     No           18.816215   \n",
       "10   26 Years and 9 Months                     No           18.816215   \n",
       "11  26 Years and 10 Months                     No           18.816215   \n",
       "12  26 Years and 11 Months                     No           18.816215   \n",
       "13   27 Years and 0 Months                     No           18.816215   \n",
       "14   27 Years and 1 Months                     NM           18.816215   \n",
       "15   27 Years and 2 Months                     No           18.816215   \n",
       "16   17 Years and 9 Months                     No          246.992319   \n",
       "17  17 Years and 10 Months                     No          246.992319   \n",
       "18  17 Years and 11 Months                     No          246.992319   \n",
       "19                     NaN                     No          246.992319   \n",
       "20   18 Years and 1 Months                     No          246.992319   \n",
       "21   18 Years and 2 Months                     No          246.992319   \n",
       "22   18 Years and 3 Months                     No          246.992319   \n",
       "23   18 Years and 4 Months                     No          246.992319   \n",
       "24   17 Years and 3 Months                     No           16.415452   \n",
       "\n",
       "   Amount_invested_monthly                 Payment_Behaviour  \\\n",
       "0        80.41529543900253   High_spent_Small_value_payments   \n",
       "1       118.28022162236736    Low_spent_Large_value_payments   \n",
       "2          81.699521264648   Low_spent_Medium_value_payments   \n",
       "3        199.4580743910713    Low_spent_Small_value_payments   \n",
       "4       41.420153086217326  High_spent_Medium_value_payments   \n",
       "5       62.430172331195294                            !@9#%8   \n",
       "6        178.3440674122349    Low_spent_Small_value_payments   \n",
       "7       24.785216509052056  High_spent_Medium_value_payments   \n",
       "8         104.291825168246    Low_spent_Small_value_payments   \n",
       "9        40.39123782853101   High_spent_Large_value_payments   \n",
       "10       58.51597569589465   High_spent_Large_value_payments   \n",
       "11       99.30622796053305   Low_spent_Medium_value_payments   \n",
       "12      130.11542024292334    Low_spent_Small_value_payments   \n",
       "13      43.477190144355745   High_spent_Large_value_payments   \n",
       "14       70.10177420755677  High_spent_Medium_value_payments   \n",
       "15      218.90434353388733    Low_spent_Small_value_payments   \n",
       "16        168.413702679309                            !@9#%8   \n",
       "17      232.86038375993544   High_spent_Small_value_payments   \n",
       "18               __10000__   High_spent_Small_value_payments   \n",
       "19       825.2162699393922   Low_spent_Medium_value_payments   \n",
       "20       430.9475278803298    Low_spent_Large_value_payments   \n",
       "21      257.80809942568976  High_spent_Medium_value_payments   \n",
       "22      263.17416316163934   High_spent_Small_value_payments   \n",
       "23               __10000__   High_spent_Small_value_payments   \n",
       "24       81.22885871073616    Low_spent_Large_value_payments   \n",
       "\n",
       "       Monthly_Balance Credit_Score  \n",
       "0   312.49408867943663         Good  \n",
       "1   284.62916249607184         Good  \n",
       "2    331.2098628537912         Good  \n",
       "3   223.45130972736786         Good  \n",
       "4   341.48923103222177         Good  \n",
       "5    340.4792117872438         Good  \n",
       "6    244.5653167062043         Good  \n",
       "7   358.12416760938714     Standard  \n",
       "8   470.69062692529184     Standard  \n",
       "9    484.5912142650067         Good  \n",
       "10  466.46647639764313     Standard  \n",
       "11   465.6762241330048         Good  \n",
       "12   444.8670318506144         Good  \n",
       "13    481.505261949182         Good  \n",
       "14   464.8806778859809         Good  \n",
       "15  356.07810855965045         Good  \n",
       "16  1043.3159778669492         Good  \n",
       "17   998.8692967863226         Good  \n",
       "18    715.741367403555         Good  \n",
       "19   426.5134106068658         Good  \n",
       "20   810.7821526659284         Good  \n",
       "21   963.9215811205684         Good  \n",
       "22   968.5555173846187     Standard  \n",
       "23    895.494583180492     Standard  \n",
       "24   433.6047729627723     Standard  \n",
       "\n",
       "[25 rows x 28 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "df = pd.concat([train_df, test_df])\n",
    "\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Customer_ID', 'Month', 'Name', 'Age', 'SSN', 'Occupation',\n",
       "       'Annual_Income', 'Monthly_Inhand_Salary', 'Num_Bank_Accounts',\n",
       "       'Num_Credit_Card', 'Interest_Rate', 'Num_of_Loan', 'Type_of_Loan',\n",
       "       'Delay_from_due_date', 'Num_of_Delayed_Payment', 'Changed_Credit_Limit',\n",
       "       'Num_Credit_Inquiries', 'Credit_Mix', 'Outstanding_Debt',\n",
       "       'Credit_Utilization_Ratio', 'Credit_History_Age',\n",
       "       'Payment_of_Min_Amount', 'Total_EMI_per_month',\n",
       "       'Amount_invested_monthly', 'Payment_Behaviour', 'Monthly_Balance',\n",
       "       'Credit_Score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Data Cleaning and Preprocessing:**\n",
    "So many missing values, we will need to treat each column depending on the nature of the data in each column and the overall context of your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                       15000\n",
       "Monthly_Inhand_Salary      22500\n",
       "Type_of_Loan               17112\n",
       "Num_of_Delayed_Payment     10500\n",
       "Num_Credit_Inquiries        3000\n",
       "Credit_History_Age         13500\n",
       "Amount_invested_monthly     6750\n",
       "Monthly_Balance             1762\n",
       "Credit_Score               50000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "missing_values[missing_values > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Customer_ID', 'Month', 'Name', 'Age', 'Occupation', 'Annual_Income',\n",
       "       'Monthly_Inhand_Salary', 'Num_Bank_Accounts', 'Num_Credit_Card',\n",
       "       'Interest_Rate', 'Num_of_Loan', 'Type_of_Loan', 'Delay_from_due_date',\n",
       "       'Num_of_Delayed_Payment', 'Changed_Credit_Limit',\n",
       "       'Num_Credit_Inquiries', 'Credit_Mix', 'Outstanding_Debt',\n",
       "       'Credit_Utilization_Ratio', 'Credit_History_Age',\n",
       "       'Payment_of_Min_Amount', 'Total_EMI_per_month',\n",
       "       'Amount_invested_monthly', 'Payment_Behaviour', 'Monthly_Balance',\n",
       "       'Credit_Score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = ['ID','SSN']\n",
    "df = df.drop(columns=columns_to_drop) #<--- dropping columns that are not needed\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 150000 entries, 0 to 49999\n",
      "Data columns (total 18 columns):\n",
      " #   Column                   Non-Null Count   Dtype \n",
      "---  ------                   --------------   ----- \n",
      " 0   Customer_ID              150000 non-null  object\n",
      " 1   Month                    150000 non-null  object\n",
      " 2   Name                     135000 non-null  object\n",
      " 3   Age                      150000 non-null  object\n",
      " 4   Occupation               150000 non-null  object\n",
      " 5   Annual_Income            150000 non-null  object\n",
      " 6   Num_of_Loan              150000 non-null  object\n",
      " 7   Type_of_Loan             132888 non-null  object\n",
      " 8   Num_of_Delayed_Payment   139500 non-null  object\n",
      " 9   Changed_Credit_Limit     150000 non-null  object\n",
      " 10  Credit_Mix               150000 non-null  object\n",
      " 11  Outstanding_Debt         150000 non-null  object\n",
      " 12  Credit_History_Age       136500 non-null  object\n",
      " 13  Payment_of_Min_Amount    150000 non-null  object\n",
      " 14  Amount_invested_monthly  143250 non-null  object\n",
      " 15  Payment_Behaviour        150000 non-null  object\n",
      " 16  Monthly_Balance          148238 non-null  object\n",
      " 17  Credit_Score             100000 non-null  object\n",
      "dtypes: object(18)\n",
      "memory usage: 21.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.select_dtypes('O').info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Customer_ID']             = df.Customer_ID.apply(lambda x: int(x[4:], 16))\n",
    "df['Month']                   = pd.to_datetime(df.Month, format='%B').dt.month\n",
    "df['Age']                     = df['Age'].astype(str).str.replace(r'\\D', '', regex=True).astype(int)\n",
    "df['Annual_Income']           = df['Annual_Income'].str.replace(r'\\D', '', regex=True).astype(float)\n",
    "df['Num_of_Loan']             = df.Num_of_Loan.astype(str).str.replace(r'\\D', '', regex=True).astype(int)\n",
    "df['Num_of_Delayed_Payment']  = df['Num_of_Delayed_Payment'].str.replace(r'\\D', '', regex=True).astype(float)\n",
    "df['Num_Credit_Inquiries']    = df['Num_Credit_Inquiries'].astype(str).str.replace(r'\\D', '', regex=True)\n",
    "df['Num_Credit_Inquiries']    = df['Num_Credit_Inquiries'].replace('', np.nan).astype(float)\n",
    "df['Changed_Credit_Limit']    = df['Changed_Credit_Limit'].str.replace(r'_', '0').astype(float)\n",
    "df['Outstanding_Debt']        = df['Outstanding_Debt'].str.replace(r'(\\d)_', r'\\1', regex=True).astype(float)\n",
    "df['Amount_invested_monthly'] = df['Amount_invested_monthly'].replace('__10000__', np.nan).astype(float)\n",
    "df['Monthly_Balance']         = df['Monthly_Balance'].replace('__-333333333333333333333333333__', np.nan).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 26)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_check = df.copy()\n",
    "df_check.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(data):\n",
    "    if data is np.NaN or not isinstance(data, str):\n",
    "        return data\n",
    "    else:\n",
    "        return str(data).strip('_ ,\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Me\\AppData\\Local\\Temp\\ipykernel_14752\\1035433873.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df_check.applymap(text_cleaning).replace(['', 'nan', '!@9#%8', '#F%$D@*&8', 'NaN'], np.NaN)\n"
     ]
    }
   ],
   "source": [
    "df = df_check.applymap(text_cleaning).replace(['', 'nan', '!@9#%8', '#F%$D@*&8', 'NaN'], np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                       15000\n",
       "Occupation                 10500\n",
       "Monthly_Inhand_Salary      22500\n",
       "Type_of_Loan               17112\n",
       "Num_of_Delayed_Payment     10500\n",
       "Num_Credit_Inquiries        3000\n",
       "Credit_Mix                 30000\n",
       "Credit_History_Age         13500\n",
       "Amount_invested_monthly    13230\n",
       "Payment_Behaviour          11400\n",
       "Monthly_Balance             1777\n",
       "Credit_Score               50000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "missing_values[missing_values > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def FillMissingWithGroupMode(df, group_column, target_column):\n",
    "    # Function to convert None to NaN and fill NaN with the mode of the group\n",
    "    def fill_mode_per_group(data, group, column):\n",
    "        # Replace None with NaN\n",
    "        data[column] = data[column].replace([None], np.nan)\n",
    "        # Calculate and fill the mode for each group\n",
    "        filled_data = data.groupby(group)[column].transform(lambda x: x.fillna(x.mode().iloc[0]))\n",
    "        return filled_data\n",
    "\n",
    "    # Display before filling NaN\n",
    "    print(f'\\nBefore filling NaN in {target_column}:')\n",
    "    print(df[target_column].isna().sum(), \"missing values\")\n",
    "    print(df.groupby(group_column)[target_column].apply(list).head())\n",
    "\n",
    "    # Fill NaN values\n",
    "    df[target_column] = fill_mode_per_group(df, group_column, target_column)\n",
    "\n",
    "    # Display after filling NaN\n",
    "    print(f'\\nAfter filling NaN in {target_column}:')\n",
    "    print(df[target_column].isna().sum(), \"missing values\")\n",
    "    print(df.groupby(group_column)[target_column].apply(list).head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Before filling NaN in Name:\n",
      "15000 missing values\n",
      "Customer_ID\n",
      "1006    [Matthias Blamontb, Matthias Blamontb, Matthia...\n",
      "1007    [nan, Soyoung Kimu, Soyoung Kimu, Soyoung Kimu...\n",
      "1008    [Koht, Koht, Koht, Koht, Koht, Koht, Koht, nan...\n",
      "1009    [Edd, Edd, Edd, Edd, Edd, Edd, Edd, Edd, Edd, ...\n",
      "1011    [Terry Wadeu, Terry Wadeu, Terry Wadeu, Terry ...\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#<--- Name\n",
    "FillMissingWithGroupMode(df, 'Customer_ID', 'Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<--- Name\n",
    "FillMissingWithGroupMode(df, 'Customer_ID', 'Payment_Behaviour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<--- Credit_Mix\n",
    "FillMissingWithGroupMode(df, 'Customer_ID', 'Credit_Mix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<--- Occupation\n",
    "FillMissingWithGroupMode(df, 'Customer_ID', 'Occupation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<--- Type_of_Loan\n",
    "df['Type_of_Loan'] = df['Type_of_Loan'].apply(lambda x: x.lower().replace('and ', '').replace(', ', ',').strip() if pd.notna(x) else x)\n",
    "import re\n",
    "def get_Diff_Values_Colum(df_column, diff_value=[], sep=',', replace=''):\n",
    "    column = df_column.dropna()\n",
    "    for i in column:\n",
    "        if sep not in i and i not in diff_value:\n",
    "            diff_value.append(i)\n",
    "        else:\n",
    "            for data in map(lambda x:x.strip(), re.sub(replace, '', i).split(sep)):\n",
    "                if not data in diff_value:\n",
    "                    diff_value.append(data)\n",
    "    return dict(enumerate(sorted(diff_value)))\n",
    "df.groupby('Customer_ID')['Type_of_Loan'].value_counts(dropna=False)\n",
    "df['Type_of_Loan'].replace([np.NaN], 'No Data', inplace=True)\n",
    "get_Diff_Values_Colum(df['Type_of_Loan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<---Num_of_Delayed_Payment\n",
    "percentile_95 = df['Num_of_Delayed_Payment'].quantile(0.95)\n",
    "df['Num_of_Delayed_Payment'] = df['Num_of_Delayed_Payment'].apply(lambda x: percentile_95 if x > percentile_95 else x)\n",
    "\n",
    "df['Num_of_Delayed_Payment'] = df.groupby('Customer_ID')['Num_of_Delayed_Payment'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "overall_median = df['Num_of_Delayed_Payment'].median()\n",
    "df['Num_of_Delayed_Payment'].fillna(overall_median, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<---Num_Credit_Inquiries\n",
    "percentile_95_inquiries = df['Num_Credit_Inquiries'].quantile(0.95)\n",
    "df['Num_Credit_Inquiries'] = df['Num_Credit_Inquiries'].apply(lambda x: percentile_95_inquiries if x > percentile_95_inquiries else x)\n",
    "\n",
    "df['Num_Credit_Inquiries'] = df.groupby('Customer_ID')['Num_Credit_Inquiries'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "overall_median_inquiries = df['Num_Credit_Inquiries'].median()\n",
    "df['Num_Credit_Inquiries'].fillna(overall_median_inquiries, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<---Credit_History_Age\n",
    "def convert_to_total_months(age_str):\n",
    "    if pd.isna(age_str):\n",
    "        return None\n",
    "    parts = age_str.split(' ')\n",
    "    years = int(parts[0]) if parts[0].isdigit() else 0\n",
    "    months = int(parts[3]) if len(parts) > 3 and parts[3].isdigit() else 0\n",
    "    return years * 12 + months\n",
    "\n",
    "df['Credit_History_Age'] = df['Credit_History_Age'].apply(convert_to_total_months)\n",
    "\n",
    "df['Credit_History_Age'] = df.groupby('Customer_ID')['Credit_History_Age'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "overall_median_credit_history = df['Credit_History_Age'].median()\n",
    "df['Credit_History_Age'].fillna(overall_median_credit_history, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Customer_ID' and fill NaNs with the median per customer\n",
    "df['Amount_invested_monthly'] = df.groupby('Customer_ID')['Amount_invested_monthly'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# In case the entire 'Amount_invested_monthly' for a customer group is NaN, fill with overall median\n",
    "overall_median_investment = df['Amount_invested_monthly'].median()\n",
    "df['Amount_invested_monthly'].fillna(overall_median_investment, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<---Monthly_Balance\n",
    "df['Monthly_Balance'] = df.groupby('Customer_ID')['Monthly_Balance'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "overall_median_balance = df['Monthly_Balance'].median()\n",
    "df['Monthly_Balance'].fillna(overall_median_balance, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<--- Monthly_Inhand_Salary (Each customer had stable income in dataset)\n",
    "FillMissingWithGroupMode(df, 'Customer_ID', 'Monthly_Inhand_Salary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_outlier_ages(group):\n",
    "    if len(group) > 1:\n",
    "        mode_age = group.mode()[0]\n",
    "        group = group.apply(lambda x: x if x == mode_age else np.nan)\n",
    "    return group\n",
    "\n",
    "df['Age'] = df.groupby('Customer_ID')['Age'].transform(replace_outlier_ages)\n",
    "\n",
    "FillMissingWithGroupMode(df, 'Customer_ID', 'Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_outlier_loan(group):\n",
    "    if len(group) > 1:\n",
    "        mode_age = group.mode()[0]\n",
    "        group = group.apply(lambda x: x if x == mode_age else np.nan)\n",
    "    return group\n",
    "\n",
    "df['Num_of_Loan'] = df.groupby('Customer_ID')['Num_of_Loan'].transform(replace_outlier_loan)\n",
    "\n",
    "FillMissingWithGroupMode(df, 'Customer_ID', 'Num_of_Loan')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values[missing_values > 0] #<--- missing values are from test dataset which we merged with train dataset\n",
    "# I realized that the Credit_Score column values from test set were NaN, so I will split the data into train and test sets based on the Credit_Score column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Exploratory Data Analysis (EDA) and Handling Extreme Outliers and error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "\n",
    "def detect_outliers(dataframe):\n",
    "    outlier_indices_dict = {}\n",
    "\n",
    "    # Loop over each column in the DataFrame\n",
    "    for column in dataframe.select_dtypes(include=[np.number]).columns:\n",
    "        # Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "        Q1 = dataframe[column].quantile(0.05)\n",
    "        Q3 = dataframe[column].quantile(0.95)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Define bounds for outliers\n",
    "        lower_bound = Q1 - (1.5 * IQR)\n",
    "        upper_bound = Q3 + (1.5 * IQR)\n",
    "\n",
    "        # Find outliers\n",
    "        outliers = dataframe[(dataframe[column] < lower_bound) | (dataframe[column] > upper_bound)]\n",
    "        outlier_indices_dict[column] = outliers.index.tolist()\n",
    "\n",
    "    return outlier_indices_dict\n",
    "\n",
    "# Run the function to detect outliers in all numerical columns\n",
    "outliers_dict = detect_outliers(df)\n",
    "\n",
    "# Example to print the outliers for a column\n",
    "for column, indices in outliers_dict.items():\n",
    "    print(f\"Outliers in column {column}: {len(indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-calculate the typical income for each customer\n",
    "typical_incomes = df.groupby('Customer_ID')['Annual_Income'].median()\n",
    "\n",
    "# Merge the median income back to the original dataframe\n",
    "df = df.join(typical_incomes.rename('Median_Income'), on='Customer_ID')\n",
    "\n",
    "# Calculate the threshold for being considered an outlier\n",
    "threshold = 0.5  # You can adjust this threshold as needed\n",
    "df['Income_Lower_Threshold'] = df['Median_Income'] * (1 - threshold)\n",
    "df['Income_Upper_Threshold'] = df['Median_Income'] * (1 + threshold)\n",
    "\n",
    "# Replace outliers with the median income\n",
    "outlier_condition = (\n",
    "    (df['Annual_Income'] < df['Income_Lower_Threshold']) |\n",
    "    (df['Annual_Income'] > df['Income_Upper_Threshold'])\n",
    ")\n",
    "df.loc[outlier_condition, 'Annual_Income'] = df.loc[outlier_condition, 'Median_Income']\n",
    "\n",
    "# Drop the extra columns if you no longer need them\n",
    "df.drop(['Median_Income', 'Income_Lower_Threshold', 'Income_Upper_Threshold'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_limit = df['Annual_Income'].quantile(0.95)  # Extreme outliers\n",
    "\n",
    "df['Annual_Income'] = df['Annual_Income'].apply(lambda x: min(x, upper_limit))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['Annual_Income'], bins=50, color='blue', edgecolor='black')  # Reduced number of bins for clarity\n",
    "plt.title('Capped Distribution of Annual Income')\n",
    "plt.xlabel('Annual Income')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(9, 3))\n",
    "plt.hist(df['Age'], bins=60, color='blue', edgecolor='black')\n",
    "plt.title('Distribution of Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the upper and lower limits\n",
    "upper_limit = df['Num_Bank_Accounts'].quantile(0.95)  # For extreme outliers\n",
    "lower_limit = 0  # Minimum realistic value\n",
    "\n",
    "df['Num_Bank_Accounts'] = df['Num_Bank_Accounts'].apply(lambda x: min(max(x, lower_limit), upper_limit))\n",
    "\n",
    "plt.figure(figsize=(9, 3))\n",
    "plt.hist(df['Num_Bank_Accounts'], bins=40, color='blue', edgecolor='black')\n",
    "plt.title('Distribution of Num_Bank_Accounts')\n",
    "plt.xlabel('Num_Bank_Accounts')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the upper and lower limits\n",
    "upper_limit = df['Num_Credit_Card'].quantile(0.95)  # For extreme outliers\n",
    "lower_limit = 0  # Minimum realistic value\n",
    "\n",
    "df['Num_Credit_Card'] = df['Num_Credit_Card'].apply(lambda x: min(max(x, lower_limit), upper_limit))\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(df['Num_Credit_Card'], bins=40, color='blue', edgecolor='black')\n",
    "plt.title('Distribution of Num_Credit_Card')\n",
    "plt.xlabel('Num_Credit_Card')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_limit = df['Interest_Rate'].quantile(0.95)  # Extreme outliers\n",
    "\n",
    "df['Interest_Rate'] = df['Interest_Rate'].apply(lambda x: min(x, upper_limit))\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(df['Interest_Rate'], bins=11, color='blue', edgecolor='black')\n",
    "plt.title('Distribution of Interest_Rate')\n",
    "plt.xlabel('Interest_Rate')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_limit = df['Total_EMI_per_month'].quantile(0.95)  # Extreme outliers\n",
    "\n",
    "df['Total_EMI_per_month'] = df['Total_EMI_per_month'].apply(lambda x: min(x, upper_limit))\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(df['Total_EMI_per_month'], bins=11, color='blue', edgecolor='black')\n",
    "plt.title('Distribution of Total_EMI_per_month')\n",
    "plt.xlabel('Total_EMI_per_month')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_limit = df['Amount_invested_monthly'].quantile(0.95)  # Extreme outliers\n",
    "\n",
    "df['Amount_invested_monthly'] = df['Amount_invested_monthly'].apply(lambda x: min(x, upper_limit))\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(df['Amount_invested_monthly'], bins=11, color='blue', edgecolor='black')\n",
    "plt.title('Distribution of Amount_invested_monthly')\n",
    "plt.xlabel('Amount_invested_monthly')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Feature Engineering:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns =df.select_dtypes('O').columns\n",
    "display(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns_head = df.select_dtypes('O').head(5)\n",
    "categorical_columns_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_columns:\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    print(\"Unique values count:\", df[col].nunique())\n",
    "    print(\"Value counts:\")\n",
    "    #print(df[col].value_counts(dropna=False).head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Name', axis=1, inplace=True) #<--- dropping 'Name' column as it has too many unique values\n",
    "df = pd.get_dummies(df, columns=['Occupation', 'Credit_Mix', 'Payment_of_Min_Amount', 'Payment_Behaviour'], drop_first=True)\n",
    "\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Type_of_Loan'].value_counts(dropna=False).head(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "df['Type_of_Loan'] = df['Type_of_Loan'].str.split(',')\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "type_of_loan_mlb = pd.DataFrame(mlb.fit_transform(df['Type_of_Loan']), columns=mlb.classes_, index=df.index)\n",
    "df = df.join(type_of_loan_mlb)\n",
    "\n",
    "df.drop('Type_of_Loan', axis=1, inplace=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = df.select_dtypes('number').columns\n",
    "display(numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns_head = df.select_dtypes('number').head(10)\n",
    "numerical_columns_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_functions = ['mean', 'median', 'max', 'min', 'std']\n",
    "aggregated_df = df.groupby('Customer_ID').agg({\n",
    "    'Annual_Income': agg_functions,\n",
    "    'Num_of_Loan': agg_functions,\n",
    "    'Outstanding_Debt': agg_functions,\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns except for 'Customer_ID'\n",
    "aggregated_df.columns = ['Customer_ID'] + ['{}_{}'.format(col[0], col[1]) for col in aggregated_df.columns[1:]]\n",
    "\n",
    "# Merge the DataFrames\n",
    "df = df.merge(aggregated_df, on='Customer_ID', how='left')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new feature as the ratio of Outstanding_Debt to Annual_Income\n",
    "df['Debt_Income_Ratio'] = df['Outstanding_Debt'] / df['Annual_Income']\n",
    "\n",
    "# Calculate the ratio of Monthly_Balance to Monthly_Inhand_Salary\n",
    "df['Balance_Salary_Ratio'] = df['Monthly_Balance'] / df['Monthly_Inhand_Salary']\n",
    "\n",
    "# Calculate the ratio of Total_EMI_per_month to Monthly_Inhand_Salary\n",
    "df['EMI_Salary_Ratio'] = df['Total_EMI_per_month'] / df['Monthly_Inhand_Salary']\n",
    "\n",
    "# Calculate the ratio of Outstanding_Debt to Annual_Income\n",
    "df['Debt_Income_Ratio'] = df['Outstanding_Debt'] / df['Annual_Income']\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def credit_utilization_category(ratio):\n",
    "    if ratio < 30:\n",
    "        return 'Low'\n",
    "    elif ratio < 60:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "# Apply the function to create a new categorical feature\n",
    "df['Credit_Utilization_Category'] = df['Credit_Utilization_Ratio'].apply(credit_utilization_category)\n",
    "\n",
    "# One-hot encoding of the new categorical feature\n",
    "df = pd.get_dummies(df, columns=['Credit_Utilization_Category'], drop_first=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Splitting the data: reminder that original test.csv target variable was already dropped**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = df.drop(columns=['Customer_ID'], errors='ignore') #<--- dropping 'Customer_ID' column as it is not needed for training\n",
    "#<--- Splitting the data into train and test sets\n",
    "train_set = df[df['Credit_Score'].notna()]\n",
    "test_set = df[df['Credit_Score'].isna()]\n",
    "\n",
    "#<--- remove the target variable from the test set (it is already missing, so just for precaution)\n",
    "test_set = test_set.drop(columns=['Credit_Score'], errors='ignore')\n",
    "\n",
    "# Splitting the train_set further into training and validation sets\n",
    "X = train_set.drop('Credit_Score', axis=1)  # Features\n",
    "y = train_set['Credit_Score']  # Target variable\n",
    "\n",
    "#<--- for performance review (train_set)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#<--- for final predictions (test_set)\n",
    "X_test = test_set\n",
    "\n",
    "\n",
    "#<--- This is most because We initially had Trainv.csv and Testv.csv, but we merged them together to do the data cleaning and feature engineering consistently on both datasets. Now, we will split them back into train and test sets.\n",
    "#<--- but part of our data has missing Credit_Score missing. Based on that we can't measure the performance of our model. So, we will split the data into train and test sets.\n",
    "#<--- So we will use train_set for training and validation sets and test_set for final predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "train_df = df[df['Credit_Score'].notna()]   #<--- Splitting the data into train and test sets\n",
    "test_df = df[df['Credit_Score'].isna()].drop(columns=['Credit_Score'], errors='ignore')\n",
    "\n",
    "X = train_df.drop(columns=['Credit_Score'])\n",
    "y = train_df['Credit_Score']\n",
    "groups = train_df['Customer_ID']  # Groups for GroupKFold\n",
    "\n",
    "#<--- i decided to use GroupKFold because the dataset has customers with multiple rows. So, I want to make sure that the same customer doesn't appear in both training and validation sets. This is to avoid data leakage and overfitting.\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "train_idx, valid_idx = next(gkf.split(X, y, groups=groups))\n",
    "X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "#<--- now we can drop the Customer_ID column as it is not needed for training anymore\n",
    "X_train = X_train.drop(columns=['Customer_ID'])\n",
    "X_valid = X_valid.drop(columns=['Customer_ID'])\n",
    "\n",
    "\n",
    "#<--- for final predictions (test_set)\n",
    "X_test = test_df\n",
    "\n",
    "\n",
    "#<--- This is most because We initially had Trainv.csv and Testv.csv, but we merged them together to do the data cleaning and feature engineering consistently on both datasets. Now, we will split them back into train and test sets.\n",
    "#<--- but part of our data has missing Credit_Score missing. Based on that we can't measure the performance of our model. So, we will split the data into train and test sets.\n",
    "#<--- So we will use train_set for training and validation sets and test_set for final predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"inf in X_train:\", X_train.isin([np.inf, -np.inf]).sum().sum())\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Identify columns with infinite values\n",
    "inf_columns = X_train.columns[X_train.isin([np.inf, -np.inf]).any()].tolist()\n",
    "\n",
    "print(\"Columns with Infinite Values:\", inf_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"extreme values in X_train:\", X_train.abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Feature Selection: Correlation, RandomForest Importance, RFECV**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#These codes run for so long that, I preemvlively chosen RF and LightGBM as my models so that I can skip scaling.\n",
    "#I could have also engineered some features but I already have too many features.\n",
    "\n",
    "##<--- 1. Correlation Analysis on Training Data\n",
    "corr_matrix = X_train.corr()\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(corr_matrix, mask=mask, cmap='coolwarm', vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "plt.xticks(rotation=45, ha='right')  # rotate for better readability\n",
    "plt.yticks(rotation=0)  # <--- for better readability\n",
    "plt.title(\"Correlation Matrix for Training Data\")\n",
    "plt.tight_layout()  # <--- to fit\n",
    "plt.show()\n",
    "\n",
    "#<--- identify highly correlated variables (0.85)\n",
    "high_corr_var = [col for col in corr_matrix.columns if any(corr_matrix[col] > 0.85)]\n",
    "print(\"Highly correlated variables:\", high_corr_var)\n",
    "\n",
    "##<--- 2. Feature Importance with Random Forest on Training Data\n",
    "rf = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "feature_importances = pd.DataFrame(rf.feature_importances_, index=X_train.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "#<--- plot the feature importances\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.barplot(x=feature_importances['importance'], y=feature_importances.index)\n",
    "plt.title(\"Feature Importances in Training Data\")\n",
    "plt.show()\n",
    "\n",
    "##<--- 3. Recursive Feature Elimination with Cross-Validation (RFECV) on Training Data\n",
    "rfecv = RFECV(estimator=rf, step=5, cv=StratifiedKFold(5), scoring='accuracy', n_jobs=-1)\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Optimal number of features:\", rfecv.n_features_)\n",
    "\n",
    "#<--- extracting the mean cross-validation scores\n",
    "mean_scores = rfecv.cv_results_['mean_test_score']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(mean_scores) + 1), mean_scores, marker='o')\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross-validation score (nb of correct classifications)\")\n",
    "plt.title(\"RFECV - Number of Features vs. CV Score\")\n",
    "plt.show()\n",
    "\n",
    "#<--- storting final selected features\n",
    "selected_features = X_train.columns[rfecv.support_]\n",
    "print(\"Selected Features:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assume X_train, y_train, and groups are already defined\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Initialize the list to store feature importances and accuracy scores\n",
    "feature_importances_list = []\n",
    "scores = []\n",
    "\n",
    "# GroupKFold for splitting training data to avoid leakage\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "for train_index, test_index in gkf.split(X_train, y_train, groups=groups):\n",
    "    # Split the data while keeping groups together\n",
    "    X_train_fold, X_valid_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_valid_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "    # Fit the model on the training fold\n",
    "    rf.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Predict on the validation fold and calculate accuracy\n",
    "    y_valid_pred_fold = rf.predict(X_valid_fold)\n",
    "    fold_score = accuracy_score(y_valid_fold, y_valid_pred_fold)\n",
    "    scores.append(fold_score)\n",
    "\n",
    "    # Store the feature importances\n",
    "    feature_importances_list.append(rf.feature_importances_)\n",
    "\n",
    "# Calculate the average feature importances across all folds\n",
    "average_feature_importances = np.mean(feature_importances_list, axis=0)\n",
    "\n",
    "# Create a DataFrame for easy plotting and manipulation\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': average_feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.barplot(data=feature_importances_df.head(30), x='Importance', y='Feature')  # Plot top 30 for visibility\n",
    "plt.title(\"Feature Importances in Training Data\")\n",
    "plt.show()\n",
    "\n",
    "# Print the average accuracy across all folds\n",
    "print(\"Average accuracy across folds:\", np.mean(scores))\n",
    "\n",
    "# Select the top N features by importance\n",
    "N = 30  # or another number based on your analysis\n",
    "selected_features = feature_importances_df.head(N)['Feature']\n",
    "print(\"Selected Features:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming X_train, y_train, X_valid, and y_valid are already defined\n",
    "# Assuming selected_features is the list of selected features after feature selection\n",
    "\n",
    "# Training Random Forest model\n",
    "rf_classifier = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the model on the training data using only the selected features\n",
    "rf_classifier.fit(X_train[selected_features], y_train)\n",
    "\n",
    "# Predict on the training data\n",
    "y_train_pred = rf_classifier.predict(X_train[selected_features])\n",
    "\n",
    "# Calculate accuracy on the training set\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Training Set Accuracy:\", train_accuracy)\n",
    "\n",
    "# Predict on the validation data\n",
    "y_valid_pred = rf_classifier.predict(X_valid[selected_features])\n",
    "\n",
    "# Calculate accuracy on the validation set\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_pred)\n",
    "print(\"Validation Set Accuracy:\", valid_accuracy)\n",
    "\n",
    "# Optionally, print a classification report for detailed performance metrics on the validation set\n",
    "print(classification_report(y_valid, y_valid_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming rf_classifier is the trained Random Forest model\n",
    "# and X_train[selected_features], y_train are the training data and labels\n",
    "\n",
    "# Generate learning curves\n",
    "train_sizes, train_scores, valid_scores = learning_curve(\n",
    "    estimator=rf_classifier,\n",
    "    X=X_train[selected_features],\n",
    "    y=y_train,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "# Calculate mean and standard deviation for training set scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "# Calculate mean and standard deviation for validation set scores\n",
    "valid_mean = np.mean(valid_scores, axis=1)\n",
    "valid_std = np.std(valid_scores, axis=1)\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, label='Training score', color='blue', marker='o')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='blue', alpha=0.15)\n",
    "\n",
    "plt.plot(train_sizes, valid_mean, label='Cross-validation score', color='green', marker='o')\n",
    "plt.fill_between(train_sizes, valid_mean - valid_std, valid_mean + valid_std, color='green', alpha=0.15)\n",
    "\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Training Data Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_selected = X_test[selected_features]\n",
    "y_test_pred = rf_classifier.predict(X_test_selected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
